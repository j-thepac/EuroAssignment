{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.utils import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import util\n",
    "from config import *\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "paths:Paths=Paths(\n",
    "    dataLake=\"../DataLake/\"\n",
    "    ,srcSearches=\"../searches/\"\n",
    "    ,srcVisitors=\"../visitors/\"\n",
    "    ,rawSearches=\"../DataLake/raw/searches\"\n",
    "    ,rawVisitors=\"../DataLake/raw/visitors\"\n",
    "    ,ezSearches=\"../DataLake/ez/searches\"\n",
    "    ,ezVisitors=\"../DataLake/ez/visitors\"\n",
    "    ,archive=\"../archive/\"\n",
    "    ,archiveSearches=\"../archive/searches\"\n",
    "    ,archiveVisitors=\"../archive/visitors\"\n",
    ")\n",
    "util.rawZoneSetup(paths)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1: Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/09/08 07:17:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark=SparkSession\\\n",
    ".builder\\\n",
    ".appName(\"test\")\\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataIngestion(srcFolder,targetFolder,archiveFolder):\n",
    "    for f in os.listdir(srcFolder):\n",
    "        srcFile=f\"{srcFolder}/{f}\"\n",
    "        if (\".json\" not in f):os.remove(srcFile)\n",
    "        else:\n",
    "            ts=util.getTsFromFileName(f)\n",
    "            targetPath=f\"{targetFolder}/{ts}/\"\n",
    "            spark.read.json(f\"{srcFolder}/{f}\").coalesce(1).write.mode(\"append\").options(header=\"True\",compression=\"snappy\").parquet(targetPath)\n",
    "            os.rename(srcFile,f\"{archiveFolder}/{f}\")\n",
    "            logging.info(f\"Completed dataIngestion {srcFile}\")\n",
    "\n",
    "\n",
    "dataIngestion(paths.srcSearches,paths.rawSearches,paths.archiveSearches)\n",
    "dataIngestion(paths.srcVisitors,paths.rawVisitors,paths.archiveVisitors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanVisitor(df:DataFrame)->DataFrame:\n",
    "    df=df\\\n",
    "    .withColumn(\"hits_avg\",df[\"hits_avg\"].cast(IntegerType()))\\\n",
    "    .withColumn(\"logged_in\",df[\"logged_in\"].cast(BooleanType()))\\\n",
    "    .withColumn(\"visit_start\", udateHandler(df.visit_start) )\\\n",
    "    .withColumn(\"visits\",df.visits.cast(IntegerType()))\\\n",
    "    .withColumn(\"visitor_id\",trim(df.visitor_id.cast(StringType())))\n",
    "\n",
    "    df=df.withColumn(\"visit_start\", to_timestamp(df.visit_start, \"yyyy-MM-dd HH:mm:ss\"))\n",
    "    df=df.withColumn(\"date\", date_format(df.visit_start,\"yyyy-MM-dd\").cast(DateType()))\\\n",
    "    .na.fill(\"na\",[\"visitor_id\"])\n",
    "    return df\n",
    "\n",
    "def cleanSearches(df:DataFrame)->DataFrame:\n",
    "    df= df\\\n",
    "    .withColumn(\"date_time\",to_timestamp(df.date_time, \"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\"))\\\n",
    "    .withColumn(\"visitor_id\",trim(df.visitor_id.cast(StringType())))\n",
    "    \n",
    "    df=df\\\n",
    "    .withColumn(\"date\", date_format(df.date_time,\"yyyy-MM-dd\").cast(DateType()))\\\n",
    "    .na.fill(\"na\",[\"visitor_id\"])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def dateHandler(dateStr:str)->str:\n",
    "    year=dateStr.split(\"-\")[0]\n",
    "    if(len(year)==2):\n",
    "        dateStr=\"20\"+dateStr\n",
    "    return dateStr\n",
    "\n",
    "udateHandler=udf(dateHandler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root: rawVisitorPartitions = 1 , rawVisitorDF.count=9999 \n",
      "INFO:root: rawSearchesPartitions=1 , rawSearchesPartitions =13192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[date_time: string, destination_out: string, destination_ret: string, flight_date_inbound: string, flight_date_outbound: string, origin_out: string, origin_ret: string, segments: bigint, visitor_id: double]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawVisitorDF= spark.read.options(header=\"True\").options(inferSchema=\"True\").parquet(f\"{paths.rawVisitors}/*\").cache()\n",
    "logging.info(f\" rawVisitorPartitions = {rawVisitorDF.rdd.getNumPartitions()} , rawVisitorDF.count={rawVisitorDF.count()} \")\n",
    "cleanVisitorDF=rawVisitorDF.transform(cleanVisitor)\n",
    "rawVisitorDF.unpersist()\n",
    "\n",
    "rawSearchesDF= spark.read.options(header=\"True\").options(inferSchema=\"True\").parquet(f\"{paths.rawSearches}/*\").cache()\n",
    "logging.info(f\" rawSearchesPartitions={rawSearchesDF.rdd.getNumPartitions()} , rawSearchesPartitions ={rawSearchesDF.count()}\")\n",
    "cleanSearchesDF=rawSearchesDF.transform(cleanSearches)\n",
    "rawSearchesDF.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanVisitorDF.select(\"visitor_id\").filter(\"visitor_id is null\").distinct().show()\n",
    "visitorDim=cleanVisitorDF.select(\"visitor_id\").distinct().withColumn(\"visitorkey\",monotonically_increasing_id()).cache()\n",
    "# visitorDim.filter(\"visitor_id is null\").show()\n",
    "# cleanVisitorDF.join(visitorDim,[\"visitor_id\"],\"left_outer\").orderBy(asc(\"visitorkey\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|visitor_id|visitorkey|\n",
      "+----------+----------+\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "visitorDim.filter(\"visitorkey = 'null'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-------+------------------+--------+---------+------+----------+-----------+------+----+----------+\n",
      "|visitor_id|countPerday|country|first_hit_pagename|hits_avg|logged_in|region|registered|visit_start|visits|date|visitorkey|\n",
      "+----------+-----------+-------+------------------+--------+---------+------+----------+-----------+------+----+----------+\n",
      "+----------+-----------+-------+------------------+--------+---------+------+----------+-----------+------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleanVisitorDF.join(visitorDim,[\"visitor_id\"],\"left_outer\").filter(\"visitorkey is null\").show()\n",
    "# visitorDim.filter(\"visitorkey is null\").show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task3: Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "latestVisitorDF=cleanVisitorDF.groupBy(\"visitor_id\",\"date\").agg(max(\"visit_start\").alias(\"visit_start\")).cache()\n",
    "\n",
    "latestVisitorDFExtended=latestVisitorDF\\\n",
    "                        .join(cleanVisitorDF,[\"visitor_id\",\"visit_start\"])\\\n",
    "                        .select(\"visitor_id\",\"visit_start\",latestVisitorDF.date,\"country\",\"region\")\\\n",
    "                        .withColumnRenamed(\"visit_start\",\"date_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+--------------------+----------+\n",
      "|country|region|          visitor_id|      date|\n",
      "+-------+------+--------------------+----------+\n",
      "|   null|  null|1.594288968457053...|2021-03-11|\n",
      "|   null|  null|1.756565223890326...|2021-01-05|\n",
      "|   null|  null|1.988182525421821E10|2021-04-17|\n",
      "|   null|  null|2.036067340216234...|2021-04-02|\n",
      "|   null|  null|2.198028629380746...|2021-04-03|\n",
      "|   null|  null|2.463305758825798E10|2021-01-30|\n",
      "|   null|  null|2.710483719626454...|2021-03-01|\n",
      "|   null|  null|2.964895272253205E10|2021-03-12|\n",
      "|   null|  null|3.341345276463134E10|2021-01-01|\n",
      "|   null|  null|3.591424903713482E10|2021-03-16|\n",
      "|   null|  null|3.749918802270866E10|2021-05-01|\n",
      "|   null|  null|3.767071691283598E10|2021-01-25|\n",
      "|   null|  null| 3.76756188429285E10|2021-02-07|\n",
      "|   null|  null| 3.76756188429285E10|2021-05-12|\n",
      "|   null|  null|4.348108097504457E10|2021-02-22|\n",
      "|   null|  null|4.580088141862797E10|2021-03-29|\n",
      "|   null|  null|4.940985909838370...|2021-05-11|\n",
      "|   null|  null| 6.694269740300008E9|2021-04-17|\n",
      "|   null|  null| 7.278906372529375E9|2021-03-11|\n",
      "|   null|  null| 8.299299044713562E9|2021-02-19|\n",
      "+-------+------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleanSearchesDF\\\n",
    ".join(latestVisitorDFExtended,[\"visitor_id\",\"date\"],\"left_outer\")\\\n",
    ".select(\"country\",\"region\",\"visitor_id\",\"date\")\\\n",
    ".show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanSearchesDF\\\n",
    "# .join(latestVisitorDFExtended,[\"visitor_id\",\"date\"],\"left_outer\")\\\n",
    "# .filter(\"country is not null\")\\\n",
    "# .groupBy(cleanSearchesDF.date,\"country\",\"region\")\\\n",
    "# .agg(count(\"*\"))\\\n",
    "# .orderBy(desc(cleanSearchesDF.date))\\\n",
    "# .show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
